{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords as stopwords_scratch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengimport model yang sudah dilatih sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Kuliah\\Semester 5\\Aplikasi Web\\Praktikum 9\\.venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Kuliah\\Semester 5\\Aplikasi Web\\Praktikum 9\\.venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Kuliah\\Semester 5\\Aplikasi Web\\Praktikum 9\\.venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Kuliah\\Semester 5\\Aplikasi Web\\Praktikum 9\\.venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_bow = pickle.load(open(\"./model/feature-bow.p\",'rb'))\n",
    "model_nb = pickle.load(open('./model/model-nb.p', 'rb'))\n",
    "model_nn = pickle.load(open('./model/model-nn.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menginisialisasi stopwords lalu menyimpan ke bentuk csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panggil stopword ID\n",
    "list_stopwords = stopwords_scratch.words('indonesian')\n",
    "# Panggil stopword EN\n",
    "list_stopwords_en = stopwords_scratch.words('english')\n",
    "# Gabungkan ID & EN\n",
    "list_stopwords.extend(list_stopwords_en)\n",
    "# Tambah daftar stopword jika perlu\n",
    "list_stopwords.extend(['ya', 'yg', 'ga', 'yuk', 'dah', 'ngga', 'engga', 'ygy', 'gak', 'nya'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat DataFrame dari list stopwords\n",
    "stopwords_df = pd.DataFrame(list_stopwords, columns=['stopword'])\n",
    "\n",
    "# Simpan DataFrame sebagai CSV\n",
    "stopwords_df.to_csv('./data/stopwords.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengimport dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/comments.csv')\n",
    "stopword = pd.read_csv('./data/stopwords.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menginisialiasi Stemmer untuk bahasa Indonesia (mengubah kata ke bentuk dasar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat method pre processing text untuk membersihkan dataset dari emoji, karakter khusus, membuat jadi lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Hapus emoji\n",
    "    text = emoji.replace_emoji(text, replace=\"\") \n",
    "    # Hapus nama orang (jika ada pola umum, misalnya kapitalisasi atau nama-nama tertentu)\n",
    "    text = re.sub(r'\\b[A-Z][a-z]*\\b', '', text)\n",
    "    # Hapus karakter khusus, angka, dan URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|[^a-zA-Z\\s]', '', text)\n",
    "    # Konversi ke lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopword]\n",
    "    # Remove very short words (less than 2 characters)\n",
    "    tokens = [word for word in tokens if len(word) > 2]\n",
    "    # Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menerapkan method preprocess_text ke dalam df pada kolom 'comment' yang disimpan menjadi kolom 'cleaned_comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   comment cleaned_comment\n",
      "0                    30:03                \n",
      "1                    55:43                \n",
      "2                  1:34:55                \n",
      "3                    28:48                \n",
      "4  Gibraaaann MANTAPKUðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥          mantap\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Tampilkan hasil pre-processing pada beberapa baris pertama\n",
    "print(df[['comment', 'cleaned_comment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghapus string kosong pada kolom 'cleaned_comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['cleaned_comment'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menyimpan data yang telah dibersihkan ke ekstensi file csv dengan nama 'cleaned_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/cleaned_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengimport data 'cleaned_comments' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gibraaaann MANTAPKUðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥</td>\n",
       "      <td>mantap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pengen balik ke sini.  Lihat orang2 yg dulu ng...</td>\n",
       "      <td>balik sini orang dulu ngalem bocil msh teguh d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woi Tapera Tapera ok gas ok gas pretttt</td>\n",
       "      <td>gas gas pretttt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AkademisiRocky Gerung</td>\n",
       "      <td>akademisirocky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uustadzRockyvGerungprofDrAhliFilsapatnterkemuk...</td>\n",
       "      <td>uustadzrockyvgerungprofdrahlifilsapatnterkemukadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0                            Gibraaaann MANTAPKUðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥   \n",
       "1  Pengen balik ke sini.  Lihat orang2 yg dulu ng...   \n",
       "2            Woi Tapera Tapera ok gas ok gas pretttt   \n",
       "3                              AkademisiRocky Gerung   \n",
       "4  uustadzRockyvGerungprofDrAhliFilsapatnterkemuk...   \n",
       "\n",
       "                                     cleaned_comment  \n",
       "0                                             mantap  \n",
       "1  balik sini orang dulu ngalem bocil msh teguh d...  \n",
       "2                                    gas gas pretttt  \n",
       "3                                     akademisirocky  \n",
       "4  uustadzrockyvgerungprofdrahlifilsapatnterkemukadi  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = pd.read_csv('./data/cleaned_comments.csv')\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat method bernama predict_sentiment untuk memprediksi sentimen per baris dari dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sent):\n",
    "    text=str(sent)\n",
    "    # feature extraction\n",
    "    text_feature = feature_bow.transform([text])\n",
    "    # predict\n",
    "    return model_nb.predict(text_feature)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menerapkan method predict_sentiment ke dalam df pada kolom 'cleaned_comment' yang disimpan menjadi kolom 'predicted_sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gibraaaann MANTAPKUðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥</td>\n",
       "      <td>mantap</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pengen balik ke sini.  Lihat orang2 yg dulu ng...</td>\n",
       "      <td>balik sini orang dulu ngalem bocil msh teguh d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woi Tapera Tapera ok gas ok gas pretttt</td>\n",
       "      <td>gas gas pretttt</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AkademisiRocky Gerung</td>\n",
       "      <td>akademisirocky</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uustadzRockyvGerungprofDrAhliFilsapatnterkemuk...</td>\n",
       "      <td>uustadzrockyvgerungprofdrahlifilsapatnterkemukadi</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0                            Gibraaaann MANTAPKUðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥   \n",
       "1  Pengen balik ke sini.  Lihat orang2 yg dulu ng...   \n",
       "2            Woi Tapera Tapera ok gas ok gas pretttt   \n",
       "3                              AkademisiRocky Gerung   \n",
       "4  uustadzRockyvGerungprofDrAhliFilsapatnterkemuk...   \n",
       "\n",
       "                                     cleaned_comment predicted_sentiment  \n",
       "0                                             mantap            positive  \n",
       "1  balik sini orang dulu ngalem bocil msh teguh d...            negative  \n",
       "2                                    gas gas pretttt            positive  \n",
       "3                                     akademisirocky            positive  \n",
       "4  uustadzrockyvgerungprofdrahlifilsapatnterkemukadi            positive  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned['predicted_sentiment'] = data_cleaned.cleaned_comment.apply(predict_sentiment)\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menyimpan data yang telah dibersihkan ke ekstensi file csv dengan nama 'predicted_sentiment.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv('./data/predicted_sentiment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
